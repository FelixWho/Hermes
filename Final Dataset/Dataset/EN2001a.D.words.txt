i i dry-read it the last time next week yeah yeah no uh mine's gonna be mostly using the off-line but the actual stuff it's doing will be on-line but it won't be very um processor intensive or memory intensive i don't think don't think so yeah are we still gonna go for dumping it into a database are we still gonna dump it into a database 'cause if we are i reckon we should all read our classes out of the database it'll be so much easier well if we're gonna dump the part of it into a database anyway we might as well dump all the fields we want into the database calculate everything from there then we don't even have to worry that much about the underlying x_m_l_ representation we can just query it well if we're gonna do that we should try and store everything in in an x_m_l_ format as well yeah yeah well we don't even need to do that 'cause if we got our information density calculated off-line so all we do is treat the whole lot as one massive document i mean they'll it's not gonna be so big that we can't load in a information density for every utterance and we can just summarise based on that i think you can do it on-line i don't think there's really much point in doing like that when it's just gonna feed off in the end the information density measure basically and that's all calculated off-line so what you're really doing is sorting a list is the p computationally hard part of it well like the ideas we're calculating are information density all off-line first for every utterance in the whole corpus right so what you do is you say if you're looking at a series of meetings you just say well our whole document comprises of all these stuck together and then all you have to do is sort them by j information density like maybe weighted with the search terms and then extract them i don't think it's too slow to do on-line to be honest is that yeah well on the utterance level i was thinking so the utterances with the highest like mean information density well the trouble with doing it on the word level is if you want the audio to synch up you've got no way of getting in and extracting just that word i mean it's impossible for every single word oh okay yeah i don't think that will do it we'll have to buffer it well the skimming's gonna use the importance but like at first it's just gonna be i_d_f_ well mostly skimming yeah yeah well the nice thing about that is it will automatically be in sentences well more or less so it will make more sense and if you get just extract words yeah i see it but it'll need to be calculated at word level though because otherwise there won't be enough occurrences of the terms to make any meaningful sense yeah yeah i reckon you can just mean it over the sentence i think we should filter them maybe we should have like um a cut-off so it a w word only gets a value if it's above a certain threshold so anything that has less than say nought point five importance gets assigned to zero yeah that's the other th yeah i think we'll have to buffer the audio but i don't think it will be very hard i think it would be like an hour or two's work like just build an another f wave file essentially yeah i mean i bet there would be packages in memory yeah so just like unp there's bound to be like a media wave object or something like that and just build one in memory i don't know i have no idea but it must have like classes for dealing with files and if it has classes for concatenating files you can do it in memory so well what i think i might try and build is basically a class that you just feed it a linked list of um different wave-forms and it will just string them all together with maybe i don't know tenth of a second silence in between each one or something like that normalise it yeah oh yeah yeah we'll need that we also really wanna be able to search by who's speaking as well it doesn't matter 'cause all the calculation's done off-line that's easy you just like create a new x_m_l_ document in memory i don't think it's really that much of a problem because if it's too big what we can do is just well all the off-line stuff doesn't really matter and all we can do is just process a bit at a time like for summarisation say we wanted a hundred utterances in the summary just look at the meeting take the top one hundred utterances in each other meeting if it scores higher than the ones already in the summary so far just replace them and then you only have to process one meeting at a time okay so maybe we should build a b store a mean measure for the segments and meetings as well and speaker speaker and um topic segmenting we'll need as well yeah well yeah and then it'll f preserve the order when it's displayed the yeah yeah yeah i think so so we should basically make our own x_m_l_ document in memory that everyone's um module changes that rather than the underlying data and then have that x_m_l_ uh nite x_m_l_ document tied to the interface well you can make it in a file if you want mm-hmm they are utterances aren't they the segments are utterances aren't they yeah alright okay well that's easy well it's close enough isn't it it may not be exact every time but it's a so sort of size we're looking for yeah yeah yeah but why don't we just write it as a new x_m_l_ file can nite handle just loading arbitrary uh new like attributes and stuff i mean i would have thought they'd make it able to yeah so why do we need to have two x_m_l_ trees in memory at once the other thing is that would mean we'd be using their parser as well which means we wouldn't have to parse anything which be quite nice 'cause their parser is probably much faster than anything we've come up with anyway yeah i mean we can process it in chunks if it gets too big basically we can just process it all in chunks if it gets too big to load it into memory i think we probably want to store sorry i think we probably want to store um a hierarchical information density as well so like an informan mation density score for each meeting and each topic segment 'cause otherwise we'd be recalculating the same thing over and over and over again yeah and that will obviously make it much easier to display well it may not for the whole meeting but like yeah exactly yeah well we can start off like that well i was gonna start off i've v got sort of half-way through implementing one that does just i_d_f_ and then just i can change that to work on whatever yeah and it should be weighted by stuff like the hot spots and um the key-words in the search and stuff like that did he not say something about named entities so i thought he said there wasn't very many yeah yeah it's not t_f_i_d_f_ it's just inverse document frequency 'cause it's really easy to do basically there's just like for a baseline really well i'm half-way through it's not working yet but it will do um yeah and then averaging it over the utterances but it's not like um related to the corpus at all it's just working on an arbitrary text file at the moment no it would be useful to know how everyone's gonna store their things though yeah yeah well i've got like a few hours free like after this it's the most boring task yeah or at least um simple versions of them so maybe we should try doing something really simple like just displaying a whole meeting and like just being able to scroll through it or something like that yeah are you free after this how about friday then 'cause i'm off all friday uh wednesday i've got a nine 'til twelve yeah nothing in the afternoon i've got nothing in the afternoon so okay so you ha yeah where about just in appleton tower uh i'll be in um the appleton tower anyway um well i'll be there from twelve i've got some other stuff that needs done on matlab so if you're not there at twelve i can just work on that so yeah why w yeah i'm just building a dictionary oh mine's just gonna use the um hash map one in um java 'cause i'm only gonna do it on small documents it's just like bef until the information density is up and running just something to get give me something to work with so it's only gonna use quite small documents you see to start with why does it need to be classified into like different segments can we just fill a second class with junk that we don't care about like i don't know copies of shakespeare or something 'cause if what we're looking for is the um frequency statistics i don't see how that would be changed by the classification i the well there maybe another tool available yeah um i can't remember who's got it might be wordnet but one of these big corpuses has a list of stop words that you can download and they're just basically lists of really uninteresting boring words that we could filter out before we do that it's like that's one the papers i read that's um one things they did right at the beginning is they've got this big s stop-list and they just ignore all of those throughout the experiment yeah i it would be useful for me as well it uh i think that'd be useful for me as well yeah yeah well all you really wanna do is look into getting some sub-set of the icsi corpus off the dice machines 'cause i hate working on dice it's awful like so i can use my home machine ha has a c_d_ burner though has a c_d_ burner yeah the right-hand corner far right yeah how big is it without um the wav files and stuff 'cause i could just say at um going over s_c_p_ one night and just leave it going all night if i had to it's yeah i mean the wave data are obviously not gonna get off there completely really oh right i'll see if i can s_c_p_ it i suppose i've got a linux box and a windows box so broad-band put it on to c_d_ i can if i get down i can put to c_d_ yeah i'm not sure if there's enough space is how much do we get really okay yeah but i can do it from that session can't i you can compress it from a remote session and s_c_p_ it from the same session do you think yeah oh no no i was thinking of sshing just into some machine and then just scping it from there yeah i mean it has to go through the gateway but can you not do that mm i see yeah so you could just but th first uh how big are the chunks how big are the chunks you're looking at so quite small then so you could just um you could use just the same thing we used to build the big dictionary you just do that on-line 'cause that won't take long to build a little dictionary that big will it i mean just use the same tool that we use yeah yeah it doesn't need ordered no um well that's the t are you using t_f_i_d_f_ for the information density alright okay like 'cause frequency would be useful i think but um depending on the context the size and what we consider a document in the sense of calculating t_f_i_d_f_ is gonna change which might need thinking about i think it would be useful yeah well you need the raw frequency as well but um you also need how many times things occur within each document and um what we consider a document's gonna depend on our context i think 'cause if we're looking at the whole lot of meetings we'll consider each meeting a document in sort of terms of this algorithm and if we're viewing like say just a small topic segment you might look at even each utterance as a small document yeah but the thing is um it's gonna need some th th thought of how we actually maybe it doesn't actually matter maybe if you just do it once at the highest level it it will be fine but i was just thinking it might be difficult to calculate the t_f_i_d_f_ off-line for all the different levels we might want 'cause if we're gonna allow disjoint segments for example then how are we gonna know what's gonna be in context at any given time but i suppose if you just did it globally treating a meeting as a document it'd probably still be work out fine because you'd only be comparing to ones within the context uh i don't know i thought were you gonna use that in the end the information density oh sorry that's what i mean like um yeah for each word or whatever but across the whole lot is what i mean by highest level like across the whole corpus yeah but you'd probably look at each meeting as a document mm possibly are they big enough to get anything meaningful out of well yeah that is not it's not an issue you just concatenate an x_m_l_ file together but we still want to have like a notion of meetings for the user yeah sure yeah you just like whatever you want to look at you just jam together into an x_m_l_ file and that's your meeting even though bits of it may come from all over the place or whatever i mean i don't see why that's really a big problem so basically what you're saying is you can take an arbitrary amount of data and process it with the same algorithm it doesn't matter conceptually what that data is it could be a meeting it could be two utterances it could be a meeting plus half a meeting from somewhere else i don't think it's very difficult though i mean what you do is you just build an x_m_l_ file and if you want it to get down to the utterances you'd go to the leaves and then if you wanted the next level up you'd go to the parents of those and like just go from like the leaves inwards towards the branch to build up things like um you know when you click on a segment it's gonna have like words or whatever that are important as long as like the algorithms are designed um with it in mind i don't think it's a very big problem well like say you had um like say for a meeting right you've got like uh say a hierarchy that looks quite big like this and like the utterances come off of here maybe then when whatever your algorithm is doing as long as when you're working with utterances you go for all the leaves like then if you need something next up so like a topic segment you'd go to here but if you were looking at say this one so only went like this right so you it's same you'd start with the leaves and you go oh i want a topic segment so i go one layer up see and then if you're working with just a topic segment in there it's the only thing you have to worry about and like each time you want a higher level you just need to go up the tree and as long as your algorithm respects that then we can just process any arbitrary x_m_l_ file with whatever hierarchical structure we want a meeting say and that would be a topic segment so i think as long as you build an algorithm that respects whatever structure's in the file rather than imposing its own structure well no it doesn't have to be but i mean it could be as many nodes as you want like this one could be deeper maybe say so then you'd start with all your utterances here and when you go up to get topic segments you go to here here here here here here here that might be a bit confusing though 'cause you have things on different levels well wednesday yeah yeah so we'll see if we can get like a mini-browser just displays two things synched together of some kind yeah yeah it'd be useful i don't know who you see about that though i d have no idea i've probably got a reasonable amount because um everything on my dice account can actually be deleted 'cause i store it all at home as well is that guaranteed to stay the maybe you should send a support form just say we want some web space listen to yeah 'cause that'd be really useful is if we had a big directory especially for transferring stuff having said that are we allowed to take a copy of the icsi corpus something we should probably ask before we do it okay okay no me neither might be funny to see what is summarised the whole corpus as anyway i think it'd be very useful but we can just change the code is that it that's quite good yeah i could just use it with the frequency i think until the information density thing's finished that would be really useful if you're doing it in java could you um serialize the output as well as writing it to a file if you're doing it in java could you serialize the um dictionary yeah as well as writing it to a file it's really easy i don't see why it'd be any more massive than the file yeah it just saves you parsing the um file representation of it and now 'cause i would be using it in java anyway so i'd just be building the data structure again yeah but it seems like a bit silly to be parsing it over and over again kinda thing i would've thought that um i think all the collections and things implement serializable already i think they might do tonight i'll try and um i'll either work some more on uh the t_f_i_d_f_ summarizer or do the audio thing yeah do we have to demonstrate something next week yeah yeah i know i think it's 'cause we had to specify it ourselves that it's not as um like focus the specification of most um work we have to do yeah once we start doing it it will all become more or less obvious i think anyway